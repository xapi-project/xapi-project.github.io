<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Features :: XAPI Toolstack Developer Documentation</title><link>https://xapi-project.github.io/new-docs/toolstack/features/index.html</link><description>Disaster Recovery Event handling High-Availability Multi-version drivers NUMA Snapshots Tracing vGPU Xapi Storage Migration</description><generator>Hugo</generator><language>en-us</language><atom:link href="https://xapi-project.github.io/new-docs/toolstack/features/index.xml" rel="self" type="application/rss+xml"/><item><title>Disaster Recovery</title><link>https://xapi-project.github.io/new-docs/toolstack/features/DR/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/DR/index.html</guid><description>The HA feature will restart VMs after hosts have failed, but what happens if a whole site (e.g. datacenter) is lost? A disaster recovery configuration is shown in the following diagram:
We rely on the storage array’s built-in mirroring to replicate (synchronously or asynchronously: the admin’s choice) between the primary and the secondary site. When DR is enabled the VM disk data and VM metadata are written to the storage server and mirrored.</description></item><item><title>Event handling in the Control Plane - Xapi, Xenopsd and Xenstore</title><link>https://xapi-project.github.io/new-docs/toolstack/features/events/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/events/index.html</guid><description>Introduction Xapi, xenopsd and xenstore use a number of different events to obtain indications that some state changed in dom0 or in the guests. The events are used as an efficient alternative to polling all these states periodically.
xenstore provides a very configurable approach in which each and any key can be watched individually by a xenstore client. Once the value of a watched key changes, xenstore will indicate to the client that the value for that key has changed.</description></item><item><title>High-Availability</title><link>https://xapi-project.github.io/new-docs/toolstack/features/HA/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/HA/index.html</guid><description>High-Availability (HA) tries to keep VMs running, even when there are hardware failures in the resource pool, when the admin is not present. Without HA the following may happen:
during the night someone spills a cup of coffee over an FC switch; then VMs running on the affected hosts will lose access to their storage; then business-critical services will go down; then monitoring software will send a text message to an off-duty admin; then the admin will travel to the office and fix the problem by restarting the VMs elsewhere.</description></item><item><title>Multi-version drivers</title><link>https://xapi-project.github.io/new-docs/toolstack/features/MVD/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/MVD/index.html</guid><description>Linux loads device drivers on boot and every device driver exists in one version. XAPI extends this scheme such that device drivers may exist in multiple variants plus a mechanism to select the variant being loaded on boot. Such a driver is called a multi-version driver and we expect only a small subset of drivers, built and distributed by XenServer, to have this property. The following covers the background, API, and CLI for multi-version drivers in XAPI.</description></item><item><title>NUMA</title><link>https://xapi-project.github.io/new-docs/toolstack/features/NUMA/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/NUMA/index.html</guid><description>NUMA in a nutshell Systems that contain more than one CPU socket are typically built on a Non-Uniform Memory Architecture (NUMA) 12. In a NUMA system each node has fast, lower latency access to local memory.
In the diagram 3 above we have 4 NUMA nodes:
2 of those are due to 2 separate physical packages (sockets) a further 2 is due to Sub-NUMA-Clustering (aka Nodes Per Socket for AMD) where the L3 cache is split The L3 cache is shared among multiple cores, but cores 0-5 have lower latency access to one part of it, than cores 6-11, and this is also reflected by splitting memory addresses into 4 31GiB ranges in total.</description></item><item><title>Snapshots</title><link>https://xapi-project.github.io/new-docs/toolstack/features/snapshots/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/snapshots/index.html</guid><description>Snapshots represent the state of a VM, or a disk (VDI) at a point in time. They can be used for:
backups (hourly, daily, weekly etc) experiments (take snapshot, try something, revert back again) golden images (install OS, get it just right, clone it 1000s of times) Read more about the Snapshot APIs.
Disk snapshots Disks are represented in the XenAPI as VDI objects. Disk snapshots are represented as VDI objects with the flag is_a_snapshot set to true.</description></item><item><title>Tracing</title><link>https://xapi-project.github.io/new-docs/toolstack/features/Tracing/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/Tracing/index.html</guid><description>Tracing is a powerful tool for observing system behavior across multiple components, making it especially useful for debugging and performance analysis in complex environments.
By integrating OpenTelemetry (a standard that unifies OpenTracing and OpenCensus) and the Zipkin v2 protocol, XAPI enables efficient tracking and visualization of operations across internal and external systems. This facilitates detailed analysis and improves collaboration between teams.
Tracing is commonly used in high-level applications such as web services.</description></item><item><title>vGPU</title><link>https://xapi-project.github.io/new-docs/toolstack/features/VGPU/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/VGPU/index.html</guid><description>XenServer has supported passthrough for GPU devices since XenServer 6.0. Since the advent of NVIDIA’s vGPU-capable GRID K1/K2 cards it has been possible to carve up a GPU into smaller pieces yielding a more scalable solution to boosting graphics performance within virtual machines.
The K1 has four GK104 GPUs and the K2 two GK107 GPUs. Each of these will be exposed through Xapi so a host with a single K1 card will have access to four independent PGPUs.</description></item><item><title>Xapi Storage Migration</title><link>https://xapi-project.github.io/new-docs/toolstack/features/XSM/index.html</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://xapi-project.github.io/new-docs/toolstack/features/XSM/index.html</guid><description>The Xapi Storage Migration (XSM) also known as “Storage Motion” allows
a running VM to be migrated within a pool, between different hosts and different storage simultaneously; a running VM to be migrated to another pool; a disk attached to a running VM to be moved to another SR. The following diagram shows how XSM works at a high level:
The slowest part of a storage migration is migrating the storage, since virtual disks can be very large.</description></item></channel></rss>